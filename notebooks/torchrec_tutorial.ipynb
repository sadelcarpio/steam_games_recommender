{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reference: https://docs.pytorch.org/tutorials/intermediate/torchrec_intro_tutorial.html",
   "id": "4ce3954042256d00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embeddings Recap",
   "id": "9dc99ac743415100"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T02:39:39.509697Z",
     "start_time": "2025-07-15T02:39:38.084054Z"
    }
   },
   "source": [
    "import torch\n",
    "from torchrec import JaggedTensor"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:40:16.614614Z",
     "start_time": "2025-07-15T02:40:16.607019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_embeddings, embedding_dim = 10, 4\n",
    "\n",
    "# Initialize embedding table\n",
    "weights = torch.rand(num_embeddings, embedding_dim)\n",
    "print(\"Weights: \", weights)"
   ],
   "id": "c6117736721c45d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  tensor([[0.4448, 0.0612, 0.2466, 0.6927],\n",
      "        [0.0136, 0.7638, 0.5630, 0.5855],\n",
      "        [0.1150, 0.9323, 0.9310, 0.5350],\n",
      "        [0.2111, 0.3665, 0.4667, 0.3583],\n",
      "        [0.1836, 0.8943, 0.9763, 0.5469],\n",
      "        [0.1469, 0.5513, 0.7553, 0.8704],\n",
      "        [0.0461, 0.1049, 0.5266, 0.1406],\n",
      "        [0.9534, 0.1321, 0.7688, 0.7059],\n",
      "        [0.4702, 0.0154, 0.3434, 0.2470],\n",
      "        [0.4574, 0.4110, 0.8286, 0.9001]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:44:26.280487Z",
     "start_time": "2025-07-15T02:44:26.276684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pass in pre-generated weights for demonstration purposes\n",
    "embedding_collection = torch.nn.Embedding(\n",
    "    num_embeddings, embedding_dim, _weight=weights  # weights are usually random init\n",
    ")\n",
    "\n",
    "# takes the mean of index embeddings passed\n",
    "embedding_bag_collection = torch.nn.EmbeddingBag(\n",
    "    num_embeddings, embedding_dim, _weight=weights\n",
    ")\n",
    "\n",
    "print(\"Embedding Collection Table: \", embedding_collection.weight)\n",
    "print(\"Embedding Bag Collection Table: \", embedding_bag_collection.weight)"
   ],
   "id": "31bf15545c09a253",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Collection Table:  Parameter containing:\n",
      "tensor([[0.4448, 0.0612, 0.2466, 0.6927],\n",
      "        [0.0136, 0.7638, 0.5630, 0.5855],\n",
      "        [0.1150, 0.9323, 0.9310, 0.5350],\n",
      "        [0.2111, 0.3665, 0.4667, 0.3583],\n",
      "        [0.1836, 0.8943, 0.9763, 0.5469],\n",
      "        [0.1469, 0.5513, 0.7553, 0.8704],\n",
      "        [0.0461, 0.1049, 0.5266, 0.1406],\n",
      "        [0.9534, 0.1321, 0.7688, 0.7059],\n",
      "        [0.4702, 0.0154, 0.3434, 0.2470],\n",
      "        [0.4574, 0.4110, 0.8286, 0.9001]], requires_grad=True)\n",
      "Embedding Bag Collection Table:  Parameter containing:\n",
      "tensor([[0.4448, 0.0612, 0.2466, 0.6927],\n",
      "        [0.0136, 0.7638, 0.5630, 0.5855],\n",
      "        [0.1150, 0.9323, 0.9310, 0.5350],\n",
      "        [0.2111, 0.3665, 0.4667, 0.3583],\n",
      "        [0.1836, 0.8943, 0.9763, 0.5469],\n",
      "        [0.1469, 0.5513, 0.7553, 0.8704],\n",
      "        [0.0461, 0.1049, 0.5266, 0.1406],\n",
      "        [0.9534, 0.1321, 0.7688, 0.7059],\n",
      "        [0.4702, 0.0154, 0.3434, 0.2470],\n",
      "        [0.4574, 0.4110, 0.8286, 0.9001]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:48:56.136665Z",
     "start_time": "2025-07-15T02:48:56.133469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lookup rows from the embedding tables\n",
    "ids = torch.tensor([[1, 3]])\n",
    "print(\"Input row IDS: \", ids)\n",
    "embeddings = embedding_collection(ids)\n",
    "# Print out the embedding lookups\n",
    "print(\"Embedding Collection Results: \")\n",
    "print(embeddings)\n",
    "print(\"Shape: \", embeddings.shape)"
   ],
   "id": "e22ed30117733808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input row IDS:  tensor([[1, 3]])\n",
      "Embedding Collection Results: \n",
      "tensor([[[0.0136, 0.7638, 0.5630, 0.5855],\n",
      "         [0.2111, 0.3665, 0.4667, 0.3583]]], grad_fn=<EmbeddingBackward0>)\n",
      "Shape:  torch.Size([1, 2, 4])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:48:56.999283Z",
     "start_time": "2025-07-15T02:48:56.996114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.EmbeddingBag takes the mean across batch dimension of above result\n",
    "pooled_embeddings = embedding_bag_collection(ids)\n",
    "print(\"Embedding Bag Collection Results: \")\n",
    "print(pooled_embeddings)\n",
    "print(\"Shape: \", pooled_embeddings.shape)"
   ],
   "id": "af77eb1600a464c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Bag Collection Results: \n",
      "tensor([[0.1124, 0.5651, 0.5148, 0.4719]], grad_fn=<EmbeddingBagBackward0>)\n",
      "Shape:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:49:37.126134Z",
     "start_time": "2025-07-15T02:49:37.123112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Same as\n",
    "print(\"Mean: \", torch.mean(embedding_collection(ids), dim=1))"
   ],
   "id": "d40bd855bddb359b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([[0.1124, 0.5651, 0.5148, 0.4719]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TorchRec features",
   "id": "b5ebcbbbbcb5da74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:52:21.856355Z",
     "start_time": "2025-07-15T02:52:19.396627Z"
    }
   },
   "cell_type": "code",
   "source": "import torchrec",
   "id": "cfcd4c99157632ca",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`EmbeddingBagCollection`: represents a group of embedding bags\n",
    "\n",
    "Example: Create an `EmbeddingBagCollection` (EBC) with two embedding bags, 1 representing products and 1 representing users."
   ],
   "id": "5c8e1a6f53e21bf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:57:25.808207Z",
     "start_time": "2025-07-15T02:57:25.801556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ebc = torchrec.EmbeddingBagCollection(\n",
    "    device=\"cpu\",\n",
    "    tables=[\n",
    "        torchrec.EmbeddingBagConfig(\n",
    "            name=\"product_table\",\n",
    "            embedding_dim=64,\n",
    "            num_embeddings=4096,\n",
    "            feature_names=[\"product\"],\n",
    "            pooling=torchrec.PoolingType.SUM,\n",
    "        ),\n",
    "        torchrec.EmbeddingBagConfig(\n",
    "            name=\"user_table\",\n",
    "            embedding_dim=64,\n",
    "            num_embeddings=4096,\n",
    "            feature_names=[\"user\"],\n",
    "            pooling=torchrec.PoolingType.SUM,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(ebc.embedding_bags)"
   ],
   "id": "b55e822fbc0e34e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
      "  (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inspect forward method",
   "id": "c7c644c31362e269"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:58:16.191673Z",
     "start_time": "2025-07-15T02:58:16.189178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "print(inspect.getsource(ebc.forward))"
   ],
   "id": "3b339f04010b94e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(self, features: KeyedJaggedTensor) -> KeyedTensor:\n",
      "        \"\"\"\n",
      "        Args:\n",
      "            features (KeyedJaggedTensor): KJT of form [F X B X L].\n",
      "\n",
      "        Returns:\n",
      "            KeyedTensor\n",
      "        \"\"\"\n",
      "\n",
      "        pooled_embeddings: List[torch.Tensor] = []\n",
      "\n",
      "        feature_dict = features.to_dict()\n",
      "        for i, embedding_bag in enumerate(self.embedding_bags.values()):\n",
      "            for feature_name in self._feature_names[i]:\n",
      "                f = feature_dict[feature_name]\n",
      "                res = embedding_bag(\n",
      "                    input=f.values(),\n",
      "                    offsets=f.offsets(),\n",
      "                    per_sample_weights=f.weights() if self._is_weighted else None,\n",
      "                ).float()\n",
      "                pooled_embeddings.append(res)\n",
      "        data = torch.cat(pooled_embeddings, dim=1)\n",
      "        return KeyedTensor(\n",
      "            keys=self._embedding_names,\n",
      "            values=data,\n",
      "            length_per_key=self._lengths_per_embedding,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input / Output Data Types",
   "id": "a74947db65c55c49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:08:16.819205Z",
     "start_time": "2025-07-15T03:08:16.816727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Batch Size 2\n",
    "# 1 ID in example 1, 2 IDs in example 2\n",
    "id_list_feature_lengths = torch.tensor([1, 2])\n",
    "# Values (IDs) tensor: ID 5 is in example 1, ID 7, 1 is in example 2\n",
    "id_list_feature_values = torch.tensor([5, 7, 1])\n",
    "# Lengths can be converted to offsets for easy indexing\n",
    "id_list_feature_offsets = torch.cumsum(id_list_feature_lengths, dim=0)"
   ],
   "id": "5593c21d9ef578fd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:08:16.984146Z",
     "start_time": "2025-07-15T03:08:16.981545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Offsets: \", id_list_feature_offsets)\n",
    "print(\"First Batch: \", id_list_feature_values[: id_list_feature_offsets[0]])\n",
    "print(\"Second Batch: \", id_list_feature_values[id_list_feature_offsets[0] : id_list_feature_offsets[1]])"
   ],
   "id": "de062037aad2807c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets:  tensor([1, 3])\n",
      "First Batch:  tensor([5])\n",
      "Second Batch:  tensor([7, 1])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`torchrec` abstraction: `JaggedTensor`",
   "id": "84ebde1bf6912a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:11:20.586396Z",
     "start_time": "2025-07-15T03:11:20.583787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchrec import JaggedTensor\n",
    "\n",
    "jt = JaggedTensor(values=id_list_feature_values, lengths=id_list_feature_lengths)\n",
    "print(\"Offsets: \", jt.offsets())\n",
    "print(\"List of values: \", jt.to_dense())\n",
    "print(jt)"
   ],
   "id": "a5bb09b9054f7d69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets:  tensor([0, 1, 3])\n",
      "List of values:  [tensor([5]), tensor([7, 1])]\n",
      "JaggedTensor({\n",
      "    [[5], [7, 1]]\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:20:29.725375Z",
     "start_time": "2025-07-15T03:20:29.721097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchrec import KeyedJaggedTensor\n",
    "# ``JaggedTensor`` represents IDs for 1 feature, but we have multiple features in an ``EmbeddingBagCollection``\n",
    "# That's where ``KeyedJaggedTensor`` comes in! ``KeyedJaggedTensor`` is just multiple ``JaggedTensors`` for multiple id_list_feature_offsets\n",
    "# From before, we have our two features \"product\" and \"user\". Let's create ``JaggedTensors`` for both!\n",
    "product_jt = JaggedTensor(\n",
    "    values=torch.tensor([1, 2, 3, 1, 5, 7, 9]),\n",
    "    lengths=torch.tensor([3, 4]),\n",
    ")\n",
    "user_jt = JaggedTensor(\n",
    "    values=torch.tensor([2, 3, 4, 1]),\n",
    "    lengths=torch.tensor([2, 2]),\n",
    ")\n",
    "kjt = KeyedJaggedTensor.from_jt_dict({\"product\": product_jt, \"user\": user_jt})\n",
    "\n",
    "# It basically is a batch size of 2\n",
    "# Product 1 has 3 IDs, Product 2 has 4 IDs\n",
    "# User 1 has 2 IDs, User 2 also has 2 IDs\n",
    "print(\"Keys: \", kjt.keys())\n",
    "print(\"Lengths: \", kjt.lengths())\n",
    "print(\"Values: \", kjt.values())\n",
    "print(\"to_dict: \", kjt.to_dict())\n",
    "print(kjt)"
   ],
   "id": "46dbb3666b2fb1c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['product', 'user']\n",
      "Lengths:  tensor([3, 4, 2, 2])\n",
      "Values:  tensor([1, 2, 3, 1, 5, 7, 9, 2, 3, 4, 1])\n",
      "to_dict:  {'product': <torchrec.sparse.jagged_tensor.JaggedTensor object at 0x7d80cd55b750>, 'user': <torchrec.sparse.jagged_tensor.JaggedTensor object at 0x7d8154291fd0>}\n",
      "KeyedJaggedTensor({\n",
      "    \"product\": [[1, 2, 3], [1, 5, 7, 9]],\n",
      "    \"user\": [[2, 3], [4, 1]]\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:20:30.191613Z",
     "start_time": "2025-07-15T03:20:30.188673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass on the `EmbeddingCollectionBag`\n",
    "result = ebc(kjt)\n",
    "result"
   ],
   "id": "8acc69738791c892",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x7d8156e76850>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T03:20:30.712175Z",
     "start_time": "2025-07-15T03:20:30.709766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(result.keys())\n",
    "print(result.values().shape)  # Remember the embedding bag pools the multiple embeddings into one (mean)\n",
    "result_dict = result.to_dict()\n",
    "for key, embedding in result_dict.items():\n",
    "    print(key, embedding.shape)"
   ],
   "id": "b2a83f5fa242848a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product', 'user']\n",
      "torch.Size([2, 128])\n",
      "product torch.Size([2, 64])\n",
      "user torch.Size([2, 64])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distributed Training and Sharding",
   "id": "1a78d347422fdd79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4ac27f0cefc4b63b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
