{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reference: https://docs.pytorch.org/tutorials/intermediate/torchrec_intro_tutorial.html",
   "id": "4ce3954042256d00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embeddings Recap",
   "id": "9dc99ac743415100"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:19.549024Z",
     "start_time": "2025-07-15T16:29:18.802903Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:20.095917Z",
     "start_time": "2025-07-15T16:29:20.014651Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "44344f0dbc3f73e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:20.770122Z",
     "start_time": "2025-07-15T16:29:20.764564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_embeddings, embedding_dim = 10, 4\n",
    "\n",
    "# Initialize embedding table\n",
    "weights = torch.rand(num_embeddings, embedding_dim)\n",
    "print(\"Weights: \", weights)"
   ],
   "id": "c6117736721c45d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  tensor([[0.7434, 0.9344, 0.5137, 0.6649],\n",
      "        [0.6238, 0.9152, 0.2048, 0.6827],\n",
      "        [0.8833, 0.7587, 0.9536, 0.2427],\n",
      "        [0.3581, 0.8361, 0.2727, 0.3238],\n",
      "        [0.1709, 0.1559, 0.4461, 0.7244],\n",
      "        [0.6119, 0.2545, 0.9343, 0.6560],\n",
      "        [0.2828, 0.0089, 0.7649, 0.7542],\n",
      "        [0.2769, 0.1665, 0.6983, 0.4497],\n",
      "        [0.2426, 0.0923, 0.6919, 0.9160],\n",
      "        [0.9665, 0.7026, 0.1881, 0.0379]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:21.630588Z",
     "start_time": "2025-07-15T16:29:21.626463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pass in pre-generated weights for demonstration purposes\n",
    "embedding_collection = torch.nn.Embedding(\n",
    "    num_embeddings, embedding_dim, _weight=weights  # weights are usually random init\n",
    ")\n",
    "\n",
    "# takes the mean of index embeddings passed\n",
    "embedding_bag_collection = torch.nn.EmbeddingBag(\n",
    "    num_embeddings, embedding_dim, _weight=weights\n",
    ")\n",
    "\n",
    "print(\"Embedding Collection Table: \", embedding_collection.weight)\n",
    "print(\"Embedding Bag Collection Table: \", embedding_bag_collection.weight)"
   ],
   "id": "31bf15545c09a253",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Collection Table:  Parameter containing:\n",
      "tensor([[0.7434, 0.9344, 0.5137, 0.6649],\n",
      "        [0.6238, 0.9152, 0.2048, 0.6827],\n",
      "        [0.8833, 0.7587, 0.9536, 0.2427],\n",
      "        [0.3581, 0.8361, 0.2727, 0.3238],\n",
      "        [0.1709, 0.1559, 0.4461, 0.7244],\n",
      "        [0.6119, 0.2545, 0.9343, 0.6560],\n",
      "        [0.2828, 0.0089, 0.7649, 0.7542],\n",
      "        [0.2769, 0.1665, 0.6983, 0.4497],\n",
      "        [0.2426, 0.0923, 0.6919, 0.9160],\n",
      "        [0.9665, 0.7026, 0.1881, 0.0379]], requires_grad=True)\n",
      "Embedding Bag Collection Table:  Parameter containing:\n",
      "tensor([[0.7434, 0.9344, 0.5137, 0.6649],\n",
      "        [0.6238, 0.9152, 0.2048, 0.6827],\n",
      "        [0.8833, 0.7587, 0.9536, 0.2427],\n",
      "        [0.3581, 0.8361, 0.2727, 0.3238],\n",
      "        [0.1709, 0.1559, 0.4461, 0.7244],\n",
      "        [0.6119, 0.2545, 0.9343, 0.6560],\n",
      "        [0.2828, 0.0089, 0.7649, 0.7542],\n",
      "        [0.2769, 0.1665, 0.6983, 0.4497],\n",
      "        [0.2426, 0.0923, 0.6919, 0.9160],\n",
      "        [0.9665, 0.7026, 0.1881, 0.0379]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:22.128924Z",
     "start_time": "2025-07-15T16:29:22.125815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lookup rows from the embedding tables\n",
    "ids = torch.tensor([[1, 3]])\n",
    "print(\"Input row IDS: \", ids)\n",
    "embeddings = embedding_collection(ids)\n",
    "# Print out the embedding lookups\n",
    "print(\"Embedding Collection Results: \")\n",
    "print(embeddings)\n",
    "print(\"Shape: \", embeddings.shape)"
   ],
   "id": "e22ed30117733808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input row IDS:  tensor([[1, 3]])\n",
      "Embedding Collection Results: \n",
      "tensor([[[0.6238, 0.9152, 0.2048, 0.6827],\n",
      "         [0.3581, 0.8361, 0.2727, 0.3238]]], grad_fn=<EmbeddingBackward0>)\n",
      "Shape:  torch.Size([1, 2, 4])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:22.616477Z",
     "start_time": "2025-07-15T16:29:22.613519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nn.EmbeddingBag takes the mean across batch dimension of above result\n",
    "pooled_embeddings = embedding_bag_collection(ids)\n",
    "print(\"Embedding Bag Collection Results: \")\n",
    "print(pooled_embeddings)\n",
    "print(\"Shape: \", pooled_embeddings.shape)"
   ],
   "id": "af77eb1600a464c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Bag Collection Results: \n",
      "tensor([[0.4910, 0.8757, 0.2387, 0.5032]], grad_fn=<EmbeddingBagBackward0>)\n",
      "Shape:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:23.080190Z",
     "start_time": "2025-07-15T16:29:23.077238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Same as\n",
    "print(\"Mean: \", torch.mean(embedding_collection(ids), dim=1))"
   ],
   "id": "d40bd855bddb359b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([[0.4910, 0.8757, 0.2387, 0.5032]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TorchRec features",
   "id": "b5ebcbbbbcb5da74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:26.498220Z",
     "start_time": "2025-07-15T16:29:24.049622Z"
    }
   },
   "cell_type": "code",
   "source": "import torchrec",
   "id": "cfcd4c99157632ca",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`EmbeddingBagCollection`: represents a group of embedding bags\n",
    "\n",
    "Example: Create an `EmbeddingBagCollection` (EBC) with two embedding bags, 1 representing products and 1 representing users."
   ],
   "id": "5c8e1a6f53e21bf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:27.534482Z",
     "start_time": "2025-07-15T16:29:27.525507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ebc = torchrec.EmbeddingBagCollection(\n",
    "    device=\"cpu\",\n",
    "    tables=[\n",
    "        torchrec.EmbeddingBagConfig(\n",
    "            name=\"product_table\",\n",
    "            embedding_dim=64,\n",
    "            num_embeddings=4096,\n",
    "            feature_names=[\"product\"],\n",
    "            pooling=torchrec.PoolingType.SUM,\n",
    "        ),\n",
    "        torchrec.EmbeddingBagConfig(\n",
    "            name=\"user_table\",\n",
    "            embedding_dim=64,\n",
    "            num_embeddings=4096,\n",
    "            feature_names=[\"user\"],\n",
    "            pooling=torchrec.PoolingType.SUM,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "print(ebc.embedding_bags)"
   ],
   "id": "b55e822fbc0e34e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
      "  (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inspect forward method",
   "id": "c7c644c31362e269"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:29.340230Z",
     "start_time": "2025-07-15T16:29:29.337721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "print(inspect.getsource(ebc.forward))"
   ],
   "id": "3b339f04010b94e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(\n",
      "        self,\n",
      "        features: KeyedJaggedTensor,  # can also take TensorDict as input\n",
      "    ) -> KeyedTensor:\n",
      "        \"\"\"\n",
      "        Run the EmbeddingBagCollection forward pass. This method takes in a `KeyedJaggedTensor`\n",
      "        and returns a `KeyedTensor`, which is the result of pooling the embeddings for each feature.\n",
      "\n",
      "        Args:\n",
      "            features (KeyedJaggedTensor): Input KJT\n",
      "        Returns:\n",
      "            KeyedTensor\n",
      "        \"\"\"\n",
      "        flat_feature_names: List[str] = []\n",
      "        features = maybe_td_to_kjt(features, None)\n",
      "        for names in self._feature_names:\n",
      "            flat_feature_names.extend(names)\n",
      "        inverse_indices = reorder_inverse_indices(\n",
      "            inverse_indices=features.inverse_indices_or_none(),\n",
      "            feature_names=flat_feature_names,\n",
      "        )\n",
      "        pooled_embeddings: List[torch.Tensor] = []\n",
      "        feature_dict = features.to_dict()\n",
      "        for i, embedding_bag in enumerate(self.embedding_bags.values()):\n",
      "            for feature_name in self._feature_names[i]:\n",
      "                f = feature_dict[feature_name]\n",
      "                res = embedding_bag(\n",
      "                    input=f.values(),\n",
      "                    offsets=f.offsets(),\n",
      "                    per_sample_weights=f.weights() if self._is_weighted else None,\n",
      "                ).float()\n",
      "                pooled_embeddings.append(res)\n",
      "        return KeyedTensor(\n",
      "            keys=self._embedding_names,\n",
      "            values=process_pooled_embeddings(\n",
      "                pooled_embeddings=pooled_embeddings,\n",
      "                inverse_indices=inverse_indices,\n",
      "            ),\n",
      "            length_per_key=self._lengths_per_embedding,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Input / Output Data Types",
   "id": "a74947db65c55c49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:31.326525Z",
     "start_time": "2025-07-15T16:29:31.324434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Batch Size 2\n",
    "# 1 ID in example 1, 2 IDs in example 2\n",
    "id_list_feature_lengths = torch.tensor([1, 2])\n",
    "# Values (IDs) tensor: ID 5 is in example 1, ID 7, 1 is in example 2\n",
    "id_list_feature_values = torch.tensor([5, 7, 1])\n",
    "# Lengths can be converted to offsets for easy indexing\n",
    "id_list_feature_offsets = torch.cumsum(id_list_feature_lengths, dim=0)"
   ],
   "id": "5593c21d9ef578fd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:31.941386Z",
     "start_time": "2025-07-15T16:29:31.938416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Offsets: \", id_list_feature_offsets)\n",
    "print(\"First Batch: \", id_list_feature_values[: id_list_feature_offsets[0]])\n",
    "print(\"Second Batch: \", id_list_feature_values[id_list_feature_offsets[0] : id_list_feature_offsets[1]])"
   ],
   "id": "de062037aad2807c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets:  tensor([1, 3])\n",
      "First Batch:  tensor([5])\n",
      "Second Batch:  tensor([7, 1])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`torchrec` abstraction: `JaggedTensor`",
   "id": "84ebde1bf6912a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:32.702699Z",
     "start_time": "2025-07-15T16:29:32.699705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchrec import JaggedTensor\n",
    "\n",
    "jt = JaggedTensor(values=id_list_feature_values, lengths=id_list_feature_lengths)\n",
    "print(\"Offsets: \", jt.offsets())\n",
    "print(\"List of values: \", jt.to_dense())\n",
    "print(jt)"
   ],
   "id": "a5bb09b9054f7d69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offsets:  tensor([0, 1, 3])\n",
      "List of values:  [tensor([5]), tensor([7, 1])]\n",
      "JaggedTensor({\n",
      "    [[5], [7, 1]]\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:33.118759Z",
     "start_time": "2025-07-15T16:29:33.114132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchrec import KeyedJaggedTensor\n",
    "# ``JaggedTensor`` represents IDs for 1 feature, but we have multiple features in an ``EmbeddingBagCollection``\n",
    "# That's where ``KeyedJaggedTensor`` comes in! ``KeyedJaggedTensor`` is just multiple ``JaggedTensors`` for multiple id_list_feature_offsets\n",
    "# From before, we have our two features \"product\" and \"user\". Let's create ``JaggedTensors`` for both!\n",
    "product_jt = JaggedTensor(\n",
    "    values=torch.tensor([1, 2, 3, 1, 5, 7, 9]),\n",
    "    lengths=torch.tensor([3, 4]),\n",
    ")\n",
    "user_jt = JaggedTensor(\n",
    "    values=torch.tensor([2, 3, 4, 1]),\n",
    "    lengths=torch.tensor([2, 2]),\n",
    ")\n",
    "kjt = KeyedJaggedTensor.from_jt_dict({\"product\": product_jt, \"user\": user_jt})\n",
    "\n",
    "# It basically is a batch size of 2\n",
    "# Product 1 has 3 IDs, Product 2 has 4 IDs\n",
    "# User 1 has 2 IDs, User 2 also has 2 IDs\n",
    "print(\"Keys: \", kjt.keys())\n",
    "print(\"Lengths: \", kjt.lengths())\n",
    "print(\"Values: \", kjt.values())\n",
    "print(\"to_dict: \", kjt.to_dict())\n",
    "print(kjt)"
   ],
   "id": "46dbb3666b2fb1c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['product', 'user']\n",
      "Lengths:  tensor([3, 4, 2, 2])\n",
      "Values:  tensor([1, 2, 3, 1, 5, 7, 9, 2, 3, 4, 1])\n",
      "to_dict:  {'product': <torchrec.sparse.jagged_tensor.JaggedTensor object at 0x73ded3ca0f50>, 'user': <torchrec.sparse.jagged_tensor.JaggedTensor object at 0x73ded3ca2ad0>}\n",
      "KeyedJaggedTensor({\n",
      "    \"product\": [[1, 2, 3], [1, 5, 7, 9]],\n",
      "    \"user\": [[2, 3], [4, 1]]\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:33.929582Z",
     "start_time": "2025-07-15T16:29:33.926034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass on the `EmbeddingCollectionBag`\n",
    "result = ebc(kjt)\n",
    "result"
   ],
   "id": "8acc69738791c892",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x73ded379b390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:34.416504Z",
     "start_time": "2025-07-15T16:29:34.414149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(result.keys())\n",
    "print(result.values().shape)  # Remember the embedding bag pools the multiple embeddings into one (mean)\n",
    "result_dict = result.to_dict()\n",
    "for key, embedding in result_dict.items():\n",
    "    print(key, embedding.shape)"
   ],
   "id": "b2a83f5fa242848a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product', 'user']\n",
      "torch.Size([2, 128])\n",
      "product torch.Size([2, 64])\n",
      "user torch.Size([2, 64])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Distributed Training and Sharding",
   "id": "1a78d347422fdd79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Idea: distribute embeddings",
   "id": "1b36fab7ab81c97b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:35.853960Z",
     "start_time": "2025-07-15T16:29:35.850525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch.distributed as dist\n",
    "# RANK: GPU device, default 0\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "# How many devices in our \"world\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "# Localhost (local training)\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "# Port for distributed training\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "dist.init_process_group(backend=\"gloo\")\n",
    "print(f\"Distributed environment initialized: {dist}\")"
   ],
   "id": "4ac27f0cefc4b63b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed environment initialized: <module 'torch.distributed' from '/home/sadelcarpio/code/steam_games_recommender/notebooks/.venv/lib/python3.11/site-packages/torch/distributed/__init__.py'>\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Model parallel**: Distribute embedding tables across multiple GPUs. Splitting up the embeddings $\\rightarrow$ **sharding**\n",
    "\n",
    "Types of sharding: Table-Wise, Column-Wise, Row-Wise\n",
    "\n",
    "Each TorchRec module has an unsharder and sharder variant. Unsharded for prototyping, sharded for production.\n",
    "\n",
    "**Data parallel**: Replicate entire model on each GPU, and each GPU takes in a distinct batch of data (gradients are synced on the backward pass)"
   ],
   "id": "878fd7b7b070d9aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:37.129741Z",
     "start_time": "2025-07-15T16:29:37.125893Z"
    }
   },
   "cell_type": "code",
   "source": "ebc",
   "id": "197a78828b20ab9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingBagCollection(\n",
       "  (embedding_bags): ModuleDict(\n",
       "    (product_table): EmbeddingBag(4096, 64, mode='sum')\n",
       "    (user_table): EmbeddingBag(4096, 64, mode='sum')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:37.628689Z",
     "start_time": "2025-07-15T16:29:37.625819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchrec.distributed.embeddingbag import EmbeddingBagCollectionSharder\n",
    "from torchrec.distributed.planner import EmbeddingShardingPlanner, Topology\n",
    "from torchrec.distributed.types import ShardingEnv\n",
    "\n",
    "sharder = EmbeddingBagCollectionSharder()\n",
    "# `ProcessGroup` from torch.distributed\n",
    "pg = dist.GroupMember.WORLD\n",
    "assert pg is not None, \"ProcessGroup not initialized\"\n",
    "\n",
    "print(f\"Process group: {pg}\")"
   ],
   "id": "3f1633e6688628b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process group: <torch.distributed.distributed_c10d.ProcessGroup object at 0x73df82774770>\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Planner**: Helps determine the best sharding configuration\n",
    "Involves:\n",
    "- Assessing memory constraints of hardware\n",
    "- Estimate compute based on memory fetches (embedding lookups)\n",
    "- Addresses data specific factors\n",
    "- Considers other hardware specifics like bandwidth"
   ],
   "id": "5deb518c0b1956be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:40.019188Z",
     "start_time": "2025-07-15T16:29:40.000433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1 GPU anc compute on CUDA device\n",
    "planner = EmbeddingShardingPlanner(\n",
    "    topology=Topology(\n",
    "        world_size=1,\n",
    "        compute_device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plan = planner.collective_plan(ebc, [sharder], pg)\n",
    "print(f\"Sharding Plan generated: {plan}\")"
   ],
   "id": "e8efdd5d56de7171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharding Plan generated: module: \n",
      "\n",
      "    param     | sharding type | compute kernel | ranks\n",
      "------------- | ------------- | -------------- | -----\n",
      "product_table | table_wise    | fused          | [0]  \n",
      "user_table    | table_wise    | fused          | [0]  \n",
      "\n",
      "    param     | shard offsets | shard sizes |   placement  \n",
      "------------- | ------------- | ----------- | -------------\n",
      "product_table | [0, 0]        | [4096, 64]  | rank:0/cuda:0\n",
      "user_table    | [0, 0]        | [4096, 64]  | rank:0/cuda:0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:30:00.276751Z",
     "start_time": "2025-07-15T16:30:00.273676Z"
    }
   },
   "cell_type": "code",
   "source": "dir(pg)",
   "id": "3e51d8ad0943ea6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BackendType',\n",
       " 'CUSTOM',\n",
       " 'GLOO',\n",
       " 'MPI',\n",
       " 'NCCL',\n",
       " 'UCC',\n",
       " 'UNDEFINED',\n",
       " 'XCCL',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_allgather_base',\n",
       " '_backend_id',\n",
       " '_device_types',\n",
       " '_enable_collectives_timing',\n",
       " '_end_coalescing',\n",
       " '_get_backend',\n",
       " '_get_backend_name',\n",
       " '_get_sequence_number_for_group',\n",
       " '_has_hooks',\n",
       " '_id',\n",
       " '_pybind11_conduit_v1_',\n",
       " '_reduce_scatter_base',\n",
       " '_register_backend',\n",
       " '_register_on_completion_hook',\n",
       " '_set_default_backend',\n",
       " '_set_group_desc',\n",
       " '_set_group_name',\n",
       " '_set_sequence_number_for_group',\n",
       " '_start_coalescing',\n",
       " '_wait_for_pending_works',\n",
       " 'abort',\n",
       " 'allgather',\n",
       " 'allgather_coalesced',\n",
       " 'allgather_into_tensor_coalesced',\n",
       " 'allreduce',\n",
       " 'allreduce_coalesced',\n",
       " 'alltoall',\n",
       " 'alltoall_base',\n",
       " 'barrier',\n",
       " 'bound_device_id',\n",
       " 'boxed',\n",
       " 'broadcast',\n",
       " 'gather',\n",
       " 'group_desc',\n",
       " 'group_name',\n",
       " 'monitored_barrier',\n",
       " 'name',\n",
       " 'rank',\n",
       " 'recv',\n",
       " 'recv_anysource',\n",
       " 'reduce',\n",
       " 'reduce_scatter',\n",
       " 'reduce_scatter_tensor_coalesced',\n",
       " 'scatter',\n",
       " 'send',\n",
       " 'shutdown',\n",
       " 'size',\n",
       " 'unbox']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:29:41.514671Z",
     "start_time": "2025-07-15T16:29:41.357090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# After creating the static plan, shard and generate a ShardedEmbeddingBagCollection\n",
    "env = ShardingEnv.from_process_group(pg)\n",
    "sharded_ebc = sharder.shard(ebc, plan.plan[\"\"], env, torch.device(\"cuda\"))\n",
    "\n",
    "print(f\"Sharded EBC: {sharded_ebc}\")"
   ],
   "id": "343d1661536cba28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharded EBC: ShardedEmbeddingBagCollection(\n",
      "  (lookups): \n",
      "   GroupedPooledEmbeddingsLookup(\n",
      "      (_emb_modules): ModuleList(\n",
      "        (0): BatchedFusedEmbeddingBag(\n",
      "          (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "   (_output_dists): \n",
      "   TwPooledEmbeddingDist()\n",
      "  (embedding_bags): ModuleDict(\n",
      "    (product_table): Module()\n",
      "    (user_table): Module()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadelcarpio/code/steam_games_recommender/notebooks/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:859: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. \n",
      "  warnings.warn(\n",
      "/home/sadelcarpio/code/steam_games_recommender/notebooks/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:903: UserWarning: Multiple backends are registered with this ProcessGroup. We cannot determine which one is the default. Returning cpu. Please consider using other APIs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### GPU Training with LazyAwaitable\n",
    "`LazyAwaitable` type delays calculating some results as long as possible"
   ],
   "id": "97770cf49386497d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:36:12.590852Z",
     "start_time": "2025-07-15T16:36:12.588005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from torchrec.distributed.types import LazyAwaitable\n",
    "\n",
    "class ExampleAwaitable(LazyAwaitable[List[torch.Tensor]]):\n",
    "    def __init__(self, size: List[int]) -> None:\n",
    "        super().__init__()\n",
    "        self._size = size\n",
    "    def _wait_impl(self) -> torch.Tensor:\n",
    "        return torch.ones(self._size)"
   ],
   "id": "5f8ee91d23cee079",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:36:13.236230Z",
     "start_time": "2025-07-15T16:36:13.231516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "awaitable = ExampleAwaitable([3, 2])\n",
    "awaitable.wait()"
   ],
   "id": "dae30cfd2077aecd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:36:39.850390Z",
     "start_time": "2025-07-15T16:36:39.817336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kjt = kjt.to(\"cuda\")\n",
    "output = sharded_ebc(kjt)\n",
    "print(output)"
   ],
   "id": "ef00a65c36d1fa64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchrec.distributed.embeddingbag.EmbeddingBagCollectionAwaitable object at 0x73dec4d0c810>\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:38:26.978914Z",
     "start_time": "2025-07-15T16:38:26.976315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kt = output.wait()\n",
    "print(type(kt))\n",
    "print(kt.keys())\n",
    "print(kt.values().shape)\n",
    "result_dict = kt.to_dict()\n",
    "# Same output as unsharded `EmbeddingBagCollection`\n",
    "for key, embedding in result_dict.items():\n",
    "    print(key, embedding.shape)"
   ],
   "id": "db5772041e44b107",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchrec.sparse.jagged_tensor.KeyedTensor'>\n",
      "['product', 'user']\n",
      "torch.Size([2, 128])\n",
      "product torch.Size([2, 64])\n",
      "user torch.Size([2, 64])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Common APIs for distributed training and inference:\n",
    "* `input_dist`: Handles distributing inputs from GPU to GPU\n",
    "* `lookups`: Does the actual embedding lookup in an optimized, batched manner using FBGEMM TBE (?)\n",
    "* `output_dist`: Handles distributing outputs from GPU to GPU"
   ],
   "id": "de1eb9cf2e29ed7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:46:02.923793Z",
     "start_time": "2025-07-15T16:46:02.921183Z"
    }
   },
   "cell_type": "code",
   "source": "sharded_ebc",
   "id": "fd83827372f22f04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardedEmbeddingBagCollection(\n",
       "  (lookups): \n",
       "   GroupedPooledEmbeddingsLookup(\n",
       "      (_emb_modules): ModuleList(\n",
       "        (0): BatchedFusedEmbeddingBag(\n",
       "          (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "   (_input_dists): \n",
       "   TwSparseFeaturesDist(\n",
       "      (_dist): KJTAllToAll()\n",
       "    )\n",
       "   (_output_dists): \n",
       "   TwPooledEmbeddingDist(\n",
       "      (_dist): PooledEmbeddingsAllToAll()\n",
       "    )\n",
       "  (embedding_bags): ModuleDict(\n",
       "    (product_table): Module()\n",
       "    (user_table): Module()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:46:08.807933Z",
     "start_time": "2025-07-15T16:46:08.805197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Distribute input KJTs to all other GPUs and receive KJTs\n",
    "sharded_ebc._input_dists"
   ],
   "id": "18bb41325f0306e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TwSparseFeaturesDist(\n",
       "   (_dist): KJTAllToAll()\n",
       " )]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:46:14.732728Z",
     "start_time": "2025-07-15T16:46:14.730359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Distribute output embeddings to all other GPUs and receive embeddings\n",
    "sharded_ebc._output_dists"
   ],
   "id": "3ddc79146ecd3be5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TwPooledEmbeddingDist(\n",
       "   (_dist): PooledEmbeddingsAllToAll()\n",
       " )]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**FBGEMM** : provides GPU operators (kernels) optimized for performing lookups of embedding tables.",
   "id": "7bf5ac8d94aa5a03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:48:27.008391Z",
     "start_time": "2025-07-15T16:48:27.005677Z"
    }
   },
   "cell_type": "code",
   "source": "sharded_ebc._lookups",
   "id": "5ee343db23934957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GroupedPooledEmbeddingsLookup(\n",
       "   (_emb_modules): ModuleList(\n",
       "     (0): BatchedFusedEmbeddingBag(\n",
       "       (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
       "     )\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DistributedModelParallel\n",
    "DMP decides how to shard the model, and shards it. Abstracts all sharding theory above"
   ],
   "id": "5d117d7e74c18097"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:52:20.218265Z",
     "start_time": "2025-07-15T16:52:20.173704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torchrec.distributed.DistributedModelParallel(ebc, device=torch.device(\"cuda\"))\n",
    "out = model(kjt)\n",
    "out.wait()"
   ],
   "id": "730544a625f85871",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadelcarpio/code/steam_games_recommender/notebooks/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:859: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. \n",
      "  warnings.warn(\n",
      "/home/sadelcarpio/code/steam_games_recommender/notebooks/.venv/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:903: UserWarning: Multiple backends are registered with this ProcessGroup. We cannot determine which one is the default. Returning cpu. Please consider using other APIs.\n",
      "  warnings.warn(\n",
      "WARNING:root:Could not determine LOCAL_WORLD_SIZE from environment, falling back to WORLD_SIZE.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torchrec.sparse.jagged_tensor.KeyedTensor at 0x73dea2054c10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:52:27.695757Z",
     "start_time": "2025-07-15T16:52:27.693176Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "e8581598bc773740",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributedModelParallel(\n",
       "  (_dmp_wrapped_module): ShardedEmbeddingBagCollection(\n",
       "    (lookups): \n",
       "     GroupedPooledEmbeddingsLookup(\n",
       "        (_emb_modules): ModuleList(\n",
       "          (0): BatchedFusedEmbeddingBag(\n",
       "            (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "     (_input_dists): \n",
       "     TwSparseFeaturesDist(\n",
       "        (_dist): KJTAllToAll()\n",
       "      )\n",
       "     (_output_dists): \n",
       "     TwPooledEmbeddingDist(\n",
       "        (_dist): PooledEmbeddingsAllToAll()\n",
       "      )\n",
       "    (embedding_bags): ModuleDict(\n",
       "      (product_table): Module()\n",
       "      (user_table): Module()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adding an Optimizer to `EmbeddingBagCollection`",
   "id": "a23423a3b19305ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:56:13.891630Z",
     "start_time": "2025-07-15T16:56:13.889550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fbgemm_gpu.split_embedding_configs import EmbOptimType\n",
    "from torchrec.optim.optimizers import in_backward_optimizer_filter"
   ],
   "id": "9a4ec73c12eaccf6",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T16:59:18.644042Z",
     "start_time": "2025-07-15T16:59:18.620598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fused_params = {\n",
    "    \"optimizer\": EmbOptimType.EXACT_ROWWISE_ADAGRAD,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"eps\": 0.002,\n",
    "}\n",
    "# Initialize sharder with `fused_params`\n",
    "sharded_with_fused_params = EmbeddingBagCollectionSharder(fused_params=fused_params)\n",
    "sharded_ebc_fused_params = sharded_with_fused_params.shard(\n",
    "    ebc, plan.plan[\"\"], env, torch.device(\"cuda\")\n",
    ")\n",
    "print(f\"Original Sharded EBC fused optimizer: {sharded_ebc_fused_params}\")\n",
    "print(f\"Sharded EBC with fused parameters fused optimizer: {sharded_ebc_fused_params.fused_optimizer}\")\n",
    "print(f\"Type of optimizer: {type(sharded_ebc_fused_params.fused_optimizer)}\")"
   ],
   "id": "da461e60a0c7c78d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sharded EBC fused optimizer: ShardedEmbeddingBagCollection(\n",
      "  (lookups): \n",
      "   GroupedPooledEmbeddingsLookup(\n",
      "      (_emb_modules): ModuleList(\n",
      "        (0): BatchedFusedEmbeddingBag(\n",
      "          (_emb_module): SplitTableBatchedEmbeddingBagsCodegen()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "   (_output_dists): \n",
      "   TwPooledEmbeddingDist()\n",
      "  (embedding_bags): ModuleDict(\n",
      "    (product_table): Module()\n",
      "    (user_table): Module()\n",
      "  )\n",
      ")\n",
      "Sharded EBC with fused parameters fused optimizer: : EmbeddingFusedOptimizer (\n",
      "Parameter Group 0\n",
      "    lr: 0.019999999552965164\n",
      ")\n",
      "Type of optimizer: <class 'torchrec.optim.keyed.CombinedOptimizer'>\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
