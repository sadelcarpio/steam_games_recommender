{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experimenting rec approaches",
   "id": "bd82e23af48d488a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:18.038919Z",
     "start_time": "2025-09-19T05:11:13.935255Z"
    }
   },
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import torch\n",
    "import torchrec"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN_CUT_TIMESTAMP = '2017-01-01'  # Fetch reviews up to this day FOR TRAINING\n",
    "VAL_CUT_TIMESTAMP = '2018-01-01'  # Fetch reviews up to this day FOR VALIDATION"
   ],
   "id": "2d59a3e437a09288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "duckdb_conn = duckdb.connect('../data/steam.duckdb', read_only=True)",
   "id": "23f962531e19e5c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train dataset",
   "id": "28daba5c0ce680c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_games_df = duckdb_conn.sql(f\"SELECT * FROM game_features WHERE DATE(game_review_day) <= '{TRAIN_CUT_TIMESTAMP}'\")",
   "id": "eda219fc8ac7c8e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_reviews_df = duckdb_conn.sql(\n",
    "    f\"SELECT * FROM fact_reviews WHERE DATE(timestamp_created) <= '{TRAIN_CUT_TIMESTAMP}'\")"
   ],
   "id": "f55f1b1cd7a4a74d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_reviews_df.show(max_width=10)",
   "id": "24bb7c62c16dd005",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "type(train_reviews_df)",
   "id": "32829cc671484fa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dim_games_df = duckdb_conn.sql(\n",
    "    f\"SELECT * FROM dim_games WHERE DATE(game_prerelease_date) <= '{TRAIN_CUT_TIMESTAMP}'\").pl()"
   ],
   "id": "8f0c85b0978b54c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dim_users_df = duckdb_conn.sql(\n",
    "    f\"SELECT * FROM dim_users WHERE DATE(first_review_timestamp) <= '{TRAIN_CUT_TIMESTAMP}'\").pl()"
   ],
   "id": "2222724047001173",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get users and games that are new during validation period\n",
    "new_users = duckdb_conn.sql(f\"SELECT * FROM dim_users WHERE DATE(first_review_timestamp) > '{TRAIN_CUT_TIMESTAMP}' \"\n",
    "                            f\"AND DATE(first_review_timestamp) <= '{VAL_CUT_TIMESTAMP}'\").pl()\n",
    "new_games = duckdb_conn.sql(f\"SELECT * FROM dim_games WHERE DATE(game_prerelease_date) > '{TRAIN_CUT_TIMESTAMP}' \"\n",
    "                            f\"AND DATE(game_prerelease_date) <= '{VAL_CUT_TIMESTAMP}'\").pl()"
   ],
   "id": "b5604ae4d1d84915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "new_games.sort(\"game_index\")",
   "id": "a4269b04b3be4af8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This may include completely new users and games on the validation data\n",
    "val_reviews_df = duckdb_conn.sql(f\"SELECT * FROM fact_reviews WHERE DATE(timestamp_created) > '{TRAIN_CUT_TIMESTAMP}' \"\n",
    "                                 f\"AND DATE(timestamp_created) <= '{VAL_CUT_TIMESTAMP}'\").pl()"
   ],
   "id": "499c0bd6c800e2cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(val_reviews_df)",
   "id": "7f7ef398a89db54f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make sure all games and users on validation data are also present in training\n",
    "val_reviews_df = val_reviews_df.filter((~pl.col(\"game_index\").is_in(new_games[\"game_index\"].implode())) & (\n",
    "    ~pl.col(\"user_index\").is_in(new_users[\"user_index\"].implode())))"
   ],
   "id": "c56e3a169967ee1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(val_reviews_df)",
   "id": "89a5b1a47ec85d08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "entity_count = duckdb_conn.sql(\n",
    "    f\"SELECT * FROM mart_entities_cumulative WHERE review_day = '{TRAIN_CUT_TIMESTAMP}'\").pl()"
   ],
   "id": "3a287562555e86f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "duckdb_conn.close()",
   "id": "d31555a8c621aa05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_users = int(entity_count[\"cumulative_user_count\"].first())\n",
    "num_games = int(entity_count[\"cumulative_game_count\"].first())"
   ],
   "id": "4af7632d43cbae1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "num_games, num_users",
   "id": "a0ad2ed78dd0fe5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example using torchrec EmbeddingCollections",
   "id": "1f8d32851f413675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ec = torchrec.EmbeddingCollection(\n",
    "    device=torch.device(\"cpu\"),\n",
    "    tables=[\n",
    "        torchrec.EmbeddingConfig(name=\"user_index\", embedding_dim=128, num_embeddings=num_users + 1),\n",
    "        torchrec.EmbeddingConfig(name=\"game_index\", embedding_dim=128, num_embeddings=num_games + 1),\n",
    "    ]\n",
    ")"
   ],
   "id": "abf479fdf615dad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample = train_reviews_df.sample(10)\n",
    "sample"
   ],
   "id": "1a7b804cf25f1e9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features = torchrec.KeyedJaggedTensor.from_jt_dict(\n",
    "    {\n",
    "        \"user_index\": torchrec.JaggedTensor(values=torch.tensor(sample[\"user_index\"]),\n",
    "                                            lengths=torch.ones(10, dtype=torch.int32)),\n",
    "        \"game_index\": torchrec.JaggedTensor(values=torch.tensor(sample[\"game_index\"]),\n",
    "                                            lengths=torch.ones(10, dtype=torch.int32)),\n",
    "    }\n",
    ")"
   ],
   "id": "282b7a1604ea6558",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out = ec(features)\n",
    "print(out[\"user_index\"].values().shape)"
   ],
   "id": "562e9cc591d2cc2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pytorch Dataset",
   "id": "a1b24327b472070b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ReviewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pl.DataFrame):\n",
    "        self.reviews = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews.row(idx, named=True)\n",
    "        return {\n",
    "            \"user_id\": torch.tensor(review[\"user_index\"]),\n",
    "            \"game_id\": torch.tensor(review[\"game_index\"]),\n",
    "            \"voted_up\": torch.tensor(review[\"voted_up\"], dtype=torch.float)\n",
    "        }\n"
   ],
   "id": "a89b31bb2360dd2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = ReviewsDataset(train_reviews_df.filter(pl.col(\"voted_up\") == 1))\n",
    "val_dataset = ReviewsDataset(val_reviews_df.filter(pl.col(\"voted_up\") == 1))"
   ],
   "id": "9bb2200803dbb230",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(train_dataset), len(val_dataset)",
   "id": "2fccca5cf69cce4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simple PyTorch model",
   "id": "4bfc5f95810dce4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimpleRetrievalModel(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim: int, num_users: int = num_users, num_games: int = num_games):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.user_emb = torch.nn.Embedding(num_users + 1, embedding_dim)\n",
    "        self.game_emb = torch.nn.Embedding(num_games + 1, embedding_dim)\n",
    "\n",
    "    def forward(self, batch: dict[str, torch.Tensor]):\n",
    "        users = batch[\"user_id\"]\n",
    "        games = batch[\"game_id\"]\n",
    "        users_embedding = self.user_emb(users)\n",
    "        games_embedding = self.game_emb(games)\n",
    "        logits = torch.matmul(users_embedding, games_embedding.t())\n",
    "        labels = torch.arange(len(users), device=users.device)\n",
    "        return torch.nn.functional.cross_entropy(logits, labels)"
   ],
   "id": "8454c938a45aab03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "4c9ace019fa7d5b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = SimpleRetrievalModel(embedding_dim=128).to(device)",
   "id": "ac22ddf946a1e7be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, pin_memory=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, pin_memory=True)"
   ],
   "id": "6548f6b60e5b17f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "20c0e2ba5461652b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model: torch.nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    train_loader: torch.utils.data.DataLoader,\n",
    "                    val_loader: torch.utils.data.DataLoader,\n",
    "                    device: torch.device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss = model(batch)\n",
    "        print(f\"Processing batch {batch_idx + 1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss = model(batch)\n",
    "            print(f\"Processing batch {batch_idx + 1}/{len(train_loader)} - Val_Loss: {loss.item():.4f}\")\n",
    "            val_loss += loss.item()\n",
    "    return total_loss / len(train_loader), val_loss / len(val_loader)"
   ],
   "id": "141d9c4e9f713cae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_loader: torch.utils.data.DataLoader,\n",
    "          val_loader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          scheduler=None):\n",
    "    train_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, val_loss = train_one_epoch(model, optimizer, train_loader, val_loader, device)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Train loss: {train_loss:.4f} - Val loss: {val_loss:.4f}\")\n",
    "    return train_loss"
   ],
   "id": "bfc813036b280178",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loss = train(model, train_dataloader, val_dataloader, torch.optim.Adam(model.parameters(), lr=0.00001), epochs=5,\n",
    "                   device=torch.device(\"cuda\"))"
   ],
   "id": "53bae8e40bc948a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "games_review_count = train_reviews_df.group_by(\"game_index\").len().filter(pl.col(\"len\") > 100).sort(\"len\",\n",
    "                                                                                                    descending=True)\n",
    "games_review_count"
   ],
   "id": "1bdb28dd00c4500a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_rev_filtered = train_reviews_df.join(games_review_count, on=\"game_index\", how=\"inner\")",
   "id": "52a816e124b3617f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_rev_filtered",
   "id": "8455aad2371e75a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "users_reviews_count = train_reviews_df.group_by(\"user_index\").len().filter(pl.col(\"len\") > 10).sort(\"len\",\n",
    "                                                                                                    descending=True)\n",
    "users_reviews_count"
   ],
   "id": "4daabd63edb2edde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_rev_filtered2 = train_rev_filtered.join(users_reviews_count, on=\"user_index\", how=\"inner\")\n",
    "train_rev_filtered2"
   ],
   "id": "cc7c3c41541f5604",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_rev_filtered = val_reviews_df.join(games_review_count, on=\"game_index\", how=\"inner\").join(users_reviews_count,\n",
    "                                                                                              on=\"user_index\",\n",
    "                                                                                              how=\"inner\")"
   ],
   "id": "4d1a16056b32304a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_rev_filtered",
   "id": "ad0c2306c76e273b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_train = ReviewsDataset(train_rev_filtered2)\n",
    "filtered_val = ReviewsDataset(val_rev_filtered)"
   ],
   "id": "4e64a42d7911687a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filtered_train_loader = torch.utils.data.DataLoader(filtered_train, batch_size=256, shuffle=True, pin_memory=True)\n",
    "filtered_val_loader = torch.utils.data.DataLoader(filtered_val, batch_size=256, shuffle=True, pin_memory=True)"
   ],
   "id": "588c39e5fd9da491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = SimpleRetrievalModel(embedding_dim=64).to(device)",
   "id": "72a03c67ab9e9c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loss = train(model, filtered_train_loader, filtered_val_loader, torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "                   epochs=20, device=torch.device(\"cuda\"))"
   ],
   "id": "595d579777c7a57a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MLFLow test",
   "id": "255bd1590e1e750a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Optional if you didn't export MLFLOW_TRACKING_URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "mlflow.set_experiment(\"test\")\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    print(mlflow.get_artifact_uri())\n",
    "    model = LogisticRegression(max_iter=200, random_state=42).fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    mlflow.log_param(\"max_iter\", 200)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "    # Upload model artifacts to object storage and register the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"IrisClassifier\"\n",
    "    )\n",
    "\n",
    "print(\"Done. Open the MLflow UI and check the Registered Models and the run artifacts.\")\n"
   ],
   "id": "a085d6de53e836c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!curl -i http://localhost:5000/api/2.0/mlflow/logged-models/list",
   "id": "525b47c3d846bd0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:18.054352Z",
     "start_time": "2025-09-19T05:11:18.043021Z"
    }
   },
   "cell_type": "code",
   "source": "duckdb_conn = duckdb.connect('../data/steam.duckdb', read_only=True)",
   "id": "175705cfea92b7bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:18.104555Z",
     "start_time": "2025-09-19T05:11:18.087475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "duckdb_conn.sql(f\"\"\"SET s3_region='us-east-1';\n",
    "                SET s3_url_style='path';\n",
    "                SET s3_use_ssl=false;\n",
    "                SET s3_endpoint='localhost:9000';\n",
    "                SET s3_access_key_id='';\n",
    "                SET s3_secret_access_key='';\"\"\")"
   ],
   "id": "6d806bc7c9941619",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "recommended_games = duckdb_conn.sql(\n",
    "    \"SELECT game_id, game_name, game_review_month, game_num_reviews, game_num_positive_reviews,\"\n",
    "    \"game_num_negative_reviews, game_weighted_score FROM game_features\").pl()"
   ],
   "id": "fb0b38a437a848ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_data = duckdb_conn.sql(\"\"\"\n",
    "                                SELECT user_id, game_id, timestamp_created\n",
    "                                FROM training_features\n",
    "                                WHERE current_month::VARCHAR LIKE '2025-%'\n",
    "                                \"\"\").pl()"
   ],
   "id": "ae31b6dde919dc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:28.423336Z",
     "start_time": "2025-09-19T05:11:20.431274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ground_truth_users = duckdb_conn.sql(\"\"\"\n",
    "                                     WITH anchors AS (\n",
    "  SELECT DISTINCT user_id, current_month\n",
    "  FROM training_features\n",
    "  WHERE voted_up = true\n",
    "    AND strftime(current_month, '%Y') = '2025'  -- prefer date funcs over LIKE\n",
    ")\n",
    "SELECT\n",
    "  a.user_id,\n",
    "  a.current_month,\n",
    "  (\n",
    "    SELECT array_agg(f.game_id ORDER BY f.first_month, f.game_id)\n",
    "    FROM (\n",
    "      SELECT tf.game_id, MIN(tf.current_month) AS first_month\n",
    "      FROM training_features AS tf\n",
    "      WHERE tf.user_id = a.user_id\n",
    "        AND tf.voted_up = true\n",
    "        AND tf.current_month >= a.current_month\n",
    "      GROUP BY tf.game_id\n",
    "    ) AS f\n",
    "  ) AS future_game_ids\n",
    "FROM anchors AS a\n",
    "ORDER BY a.user_id, a.current_month\n",
    ";\n",
    "                                     \"\"\").pl()"
   ],
   "id": "7d66db4db01f19b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23f61fb37ad64a39afdb8214da7f9186"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ground_truth_users",
   "id": "60143bc2428fd32d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_time_ground_truth = ground_truth_users.group_by(\"user_id\").agg(pl.col(\"array_agg(game_id)\").flatten()).sort(\"user_id\")",
   "id": "37e5a228f4d57ed6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "duckdb_conn.close()",
   "id": "12a9e85942ff32af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recap\n",
    "### HitRate @ K\n",
    "* Recommended: [A, X, B, ... (K values)]\n",
    "* Relevant: [A, B, C] -> (There is at least 1 match -> Hit = 1, else Hit = 0). Average over all test set (All users)\n",
    "### Precision @ K\n",
    " Out of the first K items recommended to the user, how many were relevant (part of the ground truth)?\n",
    "* Recommended = [Terminator, James Bond, Love Actually] (K = 3)\n",
    "* Relevant (Ground Truth): [Terminator, James Bond, Iron Man, ... (can be more)]\n",
    "\n",
    "Precision @ K = (# of relevant items in top K recommendations) / K = 2 / 3 = 0.67\n",
    "\n",
    "### Recall @ K\n",
    " Out of all the items the user found relevant, how many were recommended?\n",
    " Same Example\n",
    "* Recommended = [Terminator, James Bond, Love Actually] (K = 3)\n",
    "* Relevant (Ground Truth): [Terminator, James Bond, Iron Man, 3 more relevant movies] (total = 6)\n",
    "\n",
    "Recall @ K = (# of relevant items in top K recommendations) / (# of relevant items) = 2 / 6 = 0.33\n",
    "\n",
    "### Average Precision @ K\n",
    "Weighted sum of precisions for each K\n",
    "\n",
    "### Mean Average Precision @ K\n",
    "Mean over all users of the average precision"
   ],
   "id": "5f776b75b8856027"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PopularityModel:\n",
    "    def __init__(self):\n",
    "        self.games_score: pl.DataFrame | None = None\n",
    "\n",
    "    def train(self, games_df: pl.DataFrame):\n",
    "        self.games_score = self._compute_popular_games(games_df)\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_popular_games(games: pl.DataFrame):\n",
    "        sorted_games = games.select(\n",
    "            pl.all().sort_by(\"game_num_positive_reviews\", descending=True).over(\"game_review_month\",\n",
    "                                                                                mapping_strategy=\"explode\")\n",
    "        ).sort(\"game_review_month\", descending=True)\n",
    "        return sorted_games\n",
    "\n",
    "    @staticmethod\n",
    "    def get_month_date(dt: datetime):\n",
    "        return (dt.replace(day=1) - timedelta(days=1)).replace(day=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        current_month = x[\"timestamp_created\"]\n",
    "        month_date = self.get_month_date(current_month)\n",
    "        game_id = x[\"game_id\"]\n",
    "        score = self.games_score.filter((pl.col(\"game_id\") == game_id) & (pl.col(\"game_review_month\") == month_date))\n",
    "        return score[\"game_num_positive_reviews\"].first()\n",
    "\n",
    "    def recommend(self, x, k: int):\n",
    "        current_month = x[\"current_month\"]\n",
    "        month_date = self.get_month_date(current_month)\n",
    "        recommended = self.games_score.filter(pl.col(\"game_review_month\") == month_date).limit(k).select(\"game_id\", \"game_name\").to_dicts()\n",
    "        return recommended"
   ],
   "id": "bdc80786d2f8e9e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RandomRecModel:\n",
    "    def __init__(self):\n",
    "        self.games_score: pl.DataFrame | None = None\n",
    "\n",
    "    def train(self, games_df: pl.DataFrame):\n",
    "        self.games_score = games_df\n",
    "\n",
    "    def recommend(self, x, k: int):\n",
    "        recommended = self.games_score.sample(k).select(\"game_id\", \"game_name\").to_dicts()\n",
    "        return recommended"
   ],
   "id": "d2219102b8a4f998",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RecommenderMetrics:\n",
    "    @staticmethod\n",
    "    def hitrate_at_k(ground_truth: list, recommended: list):\n",
    "        hits = 0\n",
    "        for i in range(len(ground_truth)):\n",
    "            if set(ground_truth[i]) & set(recommended[i]):\n",
    "                hits += 1\n",
    "        return hits / len(ground_truth)\n",
    "\n",
    "    @staticmethod\n",
    "    def map_at_k(self, ground_truth: list, recommended: list, k: int):\n",
    "        return sum([self.ap_at_k(actual, predicted, k) for actual, predicted in zip(ground_truth, recommended)]) / len(ground_truth)\n",
    "\n",
    "    @staticmethod\n",
    "    def ap_at_k(actual: list, predicted: list, k: int):\n",
    "        sum_precisions = 0\n",
    "        hits = 0\n",
    "        for i in range(k):\n",
    "            new_pred = predicted[i]\n",
    "            if new_pred in actual and new_pred not in predicted[:i]:\n",
    "                hits += 1\n",
    "                sum_precisions += hits / (i + 1)\n",
    "        return sum_precisions / min(k, len(actual))"
   ],
   "id": "c0f1320f71f4357b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baseline = PopularityModel()\n",
    "baseline.train(recommended_games)"
   ],
   "id": "34bba512f6e34760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_baseline = RandomRecModel()\n",
    "random_baseline.train(recommended_games.unique(\"game_id\"))"
   ],
   "id": "5376bbad0bfd7533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "random_baseline.games_score",
   "id": "a2e1a714bef21707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metrics for evaluation: HitRate @ K, MAP @ K, NDCG @ K",
   "id": "a3c47faf1497ca92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "actual = [1, 450, 345, 923, 345, 90, 988, 3456, 892]\n",
    "predicted = [3, 450, 90, 34, 56, 90, 908, 345, 56, 234]\n",
    "# By Hand:\n",
    "# K = [1, 2, 3, 4, 5]\n",
    "# Precision @ 1 = 0 / 1 = 0\n",
    "# Precision @ 2 = 1 / 2 = 0.5\n",
    "# Precision @ 3 = 2 / 3 = 0.67\n",
    "# Precision @ 4 = 2 / 4 = 0.5\n",
    "# Precision @ 5 = 2 / 5 = 0.4\n",
    "# Precision @ 6 = 2 / 6 = 0.33\n",
    "# Precision @ 7 = 2 / 7 = 0.28\n",
    "# Precision @ 8 = 3 / 8 = 0.375\n",
    "# Precision @ 9 = 3 / 9 = 0.33\n",
    "# Precision @ 10 = 3 / 10 = 0.3\n",
    "# Average Precision @ K = ( 1 / min(R, K)) * sum(P@K if k is relevant)\n",
    "# Average Precision @ 10 = ( 1 / 9 ) * (0.5 + 0.67 + 0.375) = 0.1717"
   ],
   "id": "198095c5704bd54b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metrics = RecommenderMetrics()",
   "id": "e01c759c93d31dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics.ap_at_k([1, 450, 345, 923, 345, 90, 988, 3456, 892],\n",
    "                [3, 450, 90, 34, 56, 90, 908, 345, 56, 234],\n",
    "                k=10)"
   ],
   "id": "da7f11da8148f5bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compute Baseline Metrics",
   "id": "da363eb99532c03c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ground_truth_users.filter((pl.col(\"user_id\") == 76561197960268417) & (pl.col(\"current_month\") == datetime(2025, 3, 1)))[\"future_game_ids\"].first()",
   "id": "5a5c8ac1e09daf6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ground_truth_users",
   "id": "bc4ca218afd4fdf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uids = ground_truth_users[\"user_id\"].to_list()\n",
    "months = ground_truth_users[\"current_month\"].to_list()\n",
    "futures = ground_truth_users[\"future_game_ids\"].to_list()\n",
    "future_map = dict(zip(zip(uids, months), futures))"
   ],
   "id": "7ece34f714a8a70e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_ap = 0.0\n",
    "for i, elem in enumerate(ground_truth_users.iter_rows(named=True)):\n",
    "    recs = baseline.recommend(elem, k=10)\n",
    "    game_ids = [rec[\"game_id\"] for rec in recs]\n",
    "    actual = future_map.get((elem[\"user_id\"], elem[\"current_month\"]))\n",
    "    ap_k = metrics.ap_at_k(actual, game_ids, k=10)\n",
    "    total_ap = total_ap + ap_k\n",
    "    if i % 100_000 == 0:\n",
    "        print(f\"Processed {i} users\")\n",
    "        print(f\"mean Average Precision @ 10: {total_ap / (i + 1)}\")\n",
    "print(f\"mean Average Precision @ 10: {total_ap / len(ground_truth_users)}\")"
   ],
   "id": "8a44130fbc1b57e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_ap = 0.0\n",
    "for i, elem in enumerate(ground_truth_users.iter_rows(named=True)):\n",
    "    recs = baseline.recommend(elem, k=10)\n",
    "    game_ids = [rec[\"game_id\"] for rec in recs]\n",
    "    actual = all_time_ground_truth.filter(pl.col(\"user_id\") == elem[\"user_id\"])[\"array_agg(game_id)\"].first()\n",
    "    ap_k = metrics.ap_at_k(actual, game_ids, k=10)\n",
    "    total_ap = total_ap + ap_k\n",
    "    if i % 100_000 == 0:\n",
    "        print(f\"Processed {i} users\")\n",
    "        print(f\"mean Average Precision @ 10: {total_ap / (i + 1)}\")\n",
    "print(f\"mean Average Precision @ 10: {total_ap / len(ground_truth_users)}\")"
   ],
   "id": "a4b6a50394e4f7c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_ap = 0.0\n",
    "for i, elem in enumerate(ground_truth_users.iter_rows(named=True)):\n",
    "    recs = random_baseline.recommend(elem, k=10)\n",
    "    game_ids = [rec[\"game_id\"] for rec in recs]\n",
    "    actual = all_time_ground_truth.filter(pl.col(\"user_id\") == elem[\"user_id\"])[\"array_agg(game_id)\"].first()\n",
    "    ap_k = metrics.ap_at_k(actual, game_ids, k=10)\n",
    "    total_ap = total_ap + ap_k\n",
    "    if i % 100_000 == 0:\n",
    "        print(f\"Processed {i} users\")\n",
    "        print(f\"mean Average Precision @ 10: {total_ap / (i + 1)}\")\n",
    "print(f\"mean Average Precision @ 10: {total_ap / len(ground_truth_users)}\")"
   ],
   "id": "66c822e4dad3ddd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### mlflow + Baseline Model",
   "id": "c4da20ced8fc45d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%writefile baseline.py\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "import polars as pl\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.models import set_model\n",
    "\n",
    "class PopularityPyFunc(PythonModel):\n",
    "    def __init__(self, k: int = 10):\n",
    "        self.k = k\n",
    "        self._month_to_recs = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        df = pl.read_parquet(context.artifacts[\"games_score\"]).sort(\n",
    "            [\"game_review_month\", \"game_num_positive_reviews\"],\n",
    "            descending=[False, True],\n",
    "        )\n",
    "        grouped = df.group_by(\"game_review_month\").agg(\n",
    "            pl.col(\"game_id\").head(self.k).alias(\"top_game_ids\")\n",
    "        )\n",
    "        self._month_to_recs = {\n",
    "            row[\"game_review_month\"]: row[\"top_game_ids\"]\n",
    "            for row in grouped.iter_rows(named=True)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _month_start_prev(dt: datetime):\n",
    "        return (dt.replace(day=1) - timedelta(days=1)).replace(day=1)\n",
    "\n",
    "    def predict(self, context, model_input: pl.DataFrame):\n",
    "        # assumes model_input[\"current_month\"] is datetime-like\n",
    "        return model_input[\"current_month\"].map_elements(lambda dt: self._month_to_recs.get(self._month_start_prev(dt), []))\n",
    "\n",
    "set_model(PopularityPyFunc(k=10))\n"
   ],
   "id": "ce240685af631c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "import polars as pl"
   ],
   "id": "53934834821a6c78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PopularityTrainer:\n",
    "    def fit(self, games_df: pl.DataFrame) -> pl.DataFrame:\n",
    "        return games_df.select(\n",
    "            pl.all().sort_by(\"game_num_positive_reviews\", descending=True).over(\"game_review_month\", mapping_strategy=\"explode\")).sort(\"game_review_month\", descending=True)"
   ],
   "id": "ee47161d7d1bdc66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = PopularityTrainer()\n",
    "games_score = trainer.fit(recommended_games)"
   ],
   "id": "c76906b7a6381c82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "games_score",
   "id": "c711225b24026ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tempfile, os\n",
    "mlflow.set_experiment(\"baseline\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "with mlflow.start_run(run_name=\"test-baseline\"), tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"games_score.parquet\")\n",
    "    games_score.write_parquet(path)\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=\"baseline.py\",\n",
    "        artifacts={\"games_score\": path},\n",
    "        name=\"baseline-model\",\n",
    "        registered_model_name=\"baseline-model\"\n",
    "    )"
   ],
   "id": "a964c4397e761514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_info.model_uri",
   "id": "396a090cf203703e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "my_model = mlflow.pyfunc.load_model(model_info.model_uri)",
   "id": "81973da6cef838cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:28.429062Z",
     "start_time": "2025-09-19T05:11:28.427439Z"
    }
   },
   "cell_type": "code",
   "source": "df = ground_truth_users",
   "id": "75ab9d290479fe3c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import mlflow",
   "id": "cd15c401705b895e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.models.evaluate(\n",
    "    data=df,\n",
    "    model_type=\"retriever\",\n",
    "    targets=\"future_game_ids\",\n",
    "    predictions=\"predictions\",\n",
    "    evaluators=\"default\"\n",
    ")"
   ],
   "id": "dae8654f0f1584b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from datetime import date",
   "id": "805837c2648ece3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "my_model._month_to_recs",
   "id": "206e1f39504e95c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mlflow.metrics.precision_at_k()",
   "id": "5ca6db9967b8e970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys, gamerec\n",
    "print(sys.executable, gamerec.file)"
   ],
   "id": "1dbd1c7bd3f9073a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from gamerec.models.pop_model_baseline import PopularityPyFunc",
   "id": "85a378baf4c83d7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "PopularityPyFunc()",
   "id": "d0f67204e580353b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:29.177557Z",
     "start_time": "2025-09-19T05:11:28.604984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://localhost:5000')"
   ],
   "id": "faece0a3c6cd1973",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:11:40.517081Z",
     "start_time": "2025-09-19T05:11:29.308259Z"
    }
   },
   "cell_type": "code",
   "source": "my_model = mlflow.pyfunc.load_model('models:/m-d7a6fd196be64abab05c29e7c5fb9296')",
   "id": "8a0949372b54138d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85a97ae717c5481099993178da5d2d1e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadelcarpio/code/steam_games_recommender/.venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T04:48:20.799680Z",
     "start_time": "2025-09-19T04:48:20.797620Z"
    }
   },
   "cell_type": "code",
   "source": "mini = df.sample(10, seed=1)",
   "id": "d1a172b0952d7cd9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T05:12:23.306408Z",
     "start_time": "2025-09-19T05:11:42.996451Z"
    }
   },
   "cell_type": "code",
   "source": "my_model.predict(df)",
   "id": "a538ff9aee29bbed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (8_195_291,)\n",
       "Series: 'current_month' [list[i64]]\n",
       "[\n",
       "\t[3241660, 2246340, … 413150]\n",
       "\t[2694490, 2527500, … 252490]\n",
       "\t[730, 3527290, … 322170]\n",
       "\t[3164500, 3241660, … 1086940]\n",
       "\t[1771300, 730, … 550]\n",
       "\t…\n",
       "\t[3527290, 730, … 431960]\n",
       "\t[3527290, 730, … 431960]\n",
       "\t[3527290, 730, … 431960]\n",
       "\t[3527290, 730, … 431960]\n",
       "\t[3527290, 730, … 431960]\n",
       "]"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_195_291,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>current_month</th></tr><tr><td>list[i64]</td></tr></thead><tbody><tr><td>[3241660, 2246340, … 413150]</td></tr><tr><td>[2694490, 2527500, … 252490]</td></tr><tr><td>[730, 3527290, … 322170]</td></tr><tr><td>[3164500, 3241660, … 1086940]</td></tr><tr><td>[1771300, 730, … 550]</td></tr><tr><td>&hellip;</td></tr><tr><td>[3527290, 730, … 431960]</td></tr><tr><td>[3527290, 730, … 431960]</td></tr><tr><td>[3527290, 730, … 431960]</td></tr><tr><td>[3527290, 730, … 431960]</td></tr><tr><td>[3527290, 730, … 431960]</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2af5855c4989b0ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
